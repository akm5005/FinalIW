{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code generates lagged versions of specified columns (columns_to_process) for each geographic area (GEO_ID), ensuring proper handling of edge cases like missing prior-year data for 2010 and avoiding data leakage for 2019. The processed data, including the newly created lagged columns, is saved to a new CSV file, with warnings for any missing columns in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sorted by GEO_ID and Year.\n",
      "Updated data with lagged columns saved to: /u/ak5005/Python/TASK: 1119_start_to_finish/6_feature_generation/lagged_columns.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_lag_and_fill_columns(input_file_path, output_file_path, columns_to_process):\n",
    "    \"\"\"\n",
    "    Creates lagged columns for a predefined list of columns.\n",
    "    - Ensures 2010 lagged values are NaN (no prior data).\n",
    "    - Fills 2019 lagged values with 2018 lagged values to avoid data leakage.\n",
    "\n",
    "    Parameters:\n",
    "    - input_file_path (str): Path to the input CSV file.\n",
    "    - output_file_path (str): Path to save the updated CSV file.\n",
    "    - columns_to_process (list of str): List of column names to lag.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Load the main dataset\n",
    "    df = pd.read_csv(input_file_path)\n",
    "\n",
    "    # Sort the data by GEO_ID and Year to ensure proper order\n",
    "    df = df.sort_values(by=['GEO_ID', 'Year'])\n",
    "    print(\"Data sorted by GEO_ID and Year.\")\n",
    "\n",
    "    # Loop through each column in the list\n",
    "    for col in columns_to_process:\n",
    "        if col not in df.columns:\n",
    "            print(f\"Warning: Column '{col}' not found in the dataset. Skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Create lagged column\n",
    "        lag_col_name = f\"lag_{col}\"\n",
    "        df[lag_col_name] = df.groupby('GEO_ID')[col].shift(1)\n",
    "\n",
    "        # For 2010, explicitly backfill lagged values with the same 2010 value\n",
    "        df.loc[df['Year'] == 2010, lag_col_name] = df.loc[df['Year'] == 2010, col]\n",
    "\n",
    "    # Save the updated DataFrame after processing all columns\n",
    "    df.to_csv(output_file_path, index=False)\n",
    "    print(f\"Updated data with lagged columns saved to: {output_file_path}\")\n",
    "\n",
    "# Example usage\n",
    "input_file_path = \"/Users/avakrocheski-meyer/Downloads/TASK: 1119_start_to_finish/5_target_feature_engineering/target_features.csv\"\n",
    "output_file_path = \"/Users/avakrocheski-meyer/Downloads/TASK: 1119_start_to_finish/6_feature_generation/lagged_columns.csv\"\n",
    "columns_to_process = ['TOT_HH', 'CIV_POP_18+', 'TOT_CIV_POP', 'CIV_POP_16', 'TOT_HOUSING_UNITS', 'TOT_POPULATION']\n",
    "\n",
    "process_lag_and_fill_columns(input_file_path, output_file_path, columns_to_process)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code generates lagged variables for features specified in a separate file, ensuring that data is correctly grouped and sorted by GEO_ID and Year. It handles edge cases by backfilling 2010 values and saving the updated dataset with lagged variables to a new CSV file, while providing feedback on successful or incomplete interpolations for 2010."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: All 2010 values in lag_P_3_BEDROOMS have been successfully filled.\n",
      "SUCCESS: All 2010 values in lag_P_HH_INCOME_200K_PLUS have been successfully filled.\n",
      "SUCCESS: All 2010 values in lag_P_SCHOOL_NURSERY have been successfully filled.\n",
      "SUCCESS: All 2010 values in lag_AVG_COMMUTE_TIME have been successfully filled.\n",
      "SUCCESS: All 2010 values in lag_P_GRAD_DEGREE have been successfully filled.\n",
      "SUCCESS: All 2010 values in lag_P_1_BEDROOM have been successfully filled.\n",
      "SUCCESS: All 2010 values in lag_P_1_UNIT_DETACHED have been successfully filled.\n",
      "SUCCESS: All 2010 values in lag_P_COMMUTE_PUBLIC have been successfully filled.\n",
      "SUCCESS: All 2010 values in lag_P_WORK_FINANCE have been successfully filled.\n",
      "SUCCESS: All 2010 values in lag_P_WORK_INFORMATION have been successfully filled.\n",
      "SUCCESS: All 2010 values in lag_P_HH_INCOME_50K_75K have been successfully filled.\n",
      "SUCCESS: All 2010 values in lag_P_BACHELORS_PLUS have been successfully filled.\n",
      "SUCCESS: All 2010 values in lag_P_LABOR_FORCE have been successfully filled.\n",
      "SUCCESS: All 2010 values in lag_P_3PLUS_VEHICLES have been successfully filled.\n",
      "SUCCESS: All 2010 values in lag_P_WORK_TRANSPORTATION have been successfully filled.\n",
      "SUCCESS: All 2010 values in lag_P_DIFF_HOUSE_SAME_STATE have been successfully filled.\n",
      "SUCCESS: All 2010 values in lag_P_HH_VALUE_1MIL_PLUS have been successfully filled.\n",
      "SUCCESS: All 2010 values in lag_P_WORK_PROFESSIONAL have been successfully filled.\n",
      "Data with lagged variables saved to: /u/ak5005/Python/TASK: 1119_start_to_finish/6_feature_generation/all_lagged.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "features_file_path = \"/Users/avakrocheski-meyer/Downloads/TASK: 1119_start_to_finish/3_feature_selection/final_features.csv\"\n",
    "data_file_path = \"/Users/avakrocheski-meyer/Downloads/TASK: 1119_start_to_finish/6_feature_generation/lagged_columns.csv\"\n",
    "output_file_path = \"/Users/avakrocheski-meyer/Downloads/TASK: 1119_start_to_finish/6_feature_generation/all_lagged.csv\"\n",
    "\n",
    "# Load the features from the file\n",
    "features_df = pd.read_csv(features_file_path)\n",
    "features_to_lag = features_df['Features'].tolist()  # Adjust column name if necessary\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(data_file_path)\n",
    "\n",
    "# Ensure the data is sorted by GEO_ID and Year for proper lagging\n",
    "df = df.sort_values(by=['GEO_ID', 'Year'])\n",
    "\n",
    "# Create lagged variables for each feature\n",
    "for feature in features_to_lag:\n",
    "    if feature in df.columns:\n",
    "        # Create a lagged column for the feature\n",
    "        lagged_column_name = f\"lag_{feature}\"\n",
    "        df[lagged_column_name] = df.groupby('GEO_ID')[feature].shift(1)\n",
    "\n",
    "        # For 2010, explicitly backfill lagged values with the same 2010 value\n",
    "        df.loc[df['Year'] == 2010, lagged_column_name] = df.loc[df['Year'] == 2010, feature]\n",
    "\n",
    "        # Debugging check: count remaining NaNs for 2010\n",
    "        remaining_nans = df[df['Year'] == 2010][lagged_column_name].isnull().sum()\n",
    "        if remaining_nans > 0:\n",
    "            print(f\"WARNING: {remaining_nans} missing values remain in {lagged_column_name} for 2010 after interpolation.\")\n",
    "        else:\n",
    "            print(f\"SUCCESS: All 2010 values in {lagged_column_name} have been successfully filled.\")\n",
    "\n",
    "\n",
    "# Save the updated DataFrame\n",
    "df.to_csv(output_file_path, index=False)\n",
    "print(f\"Data with lagged variables saved to: {output_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
